{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec786cf8-49d2-42ef-a256-da993ac8f3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name    Age  Gender   Salary\n",
      "0  John  25.00    Male  50000.0\n",
      "1  Jane  28.75  Female  60000.0\n",
      "2  None  30.00    Male  55000.0\n",
      "3  Anna  28.00  Female  62000.0\n",
      "4  Mark  32.00    Male  56750.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jandr\\AppData\\Local\\Temp\\ipykernel_6564\\2331548424.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
      "C:\\Users\\jandr\\AppData\\Local\\Temp\\ipykernel_6564\\2331548424.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Salary'].fillna(df['Salary'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a small dataset\n",
    "data = {\n",
    "    'Name': ['John', 'Jane', None, 'Anna', 'Mark'],\n",
    "    'Age': [25, None, 30, 28, 32],\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male'],\n",
    "    'Salary': [50000, 60000, 55000, 62000, None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Option 1: Fill missing values (for example, fill 'Age' and 'Salary' with the mean)\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "df['Salary'].fillna(df['Salary'].mean(), inplace=True)\n",
    "# Option 2: Drop rows with missing 'Name'\n",
    "# df.dropna(subset=['Name'], inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895b1db4-8fc0-4d8d-bad3-f5d578cc3353",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "To handle missing values, you have a few options:\n",
    "\n",
    "Fill missing values with a default value, mean, or median.\n",
    "Remove rows or columns with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55235037-9709-4d9b-bff1-896c6a22e58a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Option 1: Fill missing values (for example, fill 'Age' and 'Salary' with the mean)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#df['Age'].fillna(df['Age'].mean(), inplace=True)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#df['Salary'].fillna(df['Salary'].mean(), inplace=True)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Option 2: Drop rows with missing 'Name'\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Option 1: Fill missing values (for example, fill 'Age' and 'Salary' with the mean)\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "df['Salary'].fillna(df['Salary'].mean(), inplace=True)\n",
    "\n",
    "# Option 2: Drop rows with missing 'Name'\n",
    "df.dropna(subset=['Name'], inplace=True)\n",
    "# It just drops the entire set of information so instead of 5 it is now 4 names\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3af6ce41-e00d-4081-8958-8ccd947746dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age  Gender   Salary\n",
      "0  John  25.0    Male  50000.0\n",
      "1  Jane   NaN  Female  60000.0\n",
      "2  None  30.0    Male  55000.0\n",
      "3  Anna  28.0  Female  62000.0\n",
      "4  Mark  32.0    Male      NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a small dataset\n",
    "data = {\n",
    "    'Name': ['John', 'Jane', None, 'Anna', 'Mark'],\n",
    "    'Age': [25, None, 30, 28, 32],\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male'],\n",
    "    'Salary': [50000, 60000, 55000, 62000, None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deac295-b2ca-4bbd-93a4-f221bd0c1032",
   "metadata": {},
   "source": [
    "## Correcting Data Types\n",
    "Sometimes, data might be loaded as the wrong type. For example, numbers may be read as strings, so you need to convert them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3ed1220-4384-4b85-a6a2-b50106464aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age  Gender   Salary\n",
      "0  John  25.0    Male  50000.0\n",
      "1  Jane   NaN  Female  60000.0\n",
      "2  None  30.0    Male  55000.0\n",
      "3  Anna  28.0  Female  62000.0\n",
      "4  Mark  32.0    Male      NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a small dataset\n",
    "data = {\n",
    "    'Name': ['John', 'Jane', None, 'Anna', 'Mark'],\n",
    "    'Age': [25, None, 30, 28, 32],\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male'],\n",
    "    'Salary': [50000, 60000, 55000, 62000, None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# Ensure 'Age' and 'Salary' are of type float or int\n",
    "df['Age'] = df['Age'].astype(float)\n",
    "df['Salary'] = df['Salary'].astype(float)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2b2259c-7b3b-4570-aa8c-a70a06bab785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age  Gender   Salary\n",
      "0  John  25.0    Male  50000.0\n",
      "1  Jane   NaN  Female  60000.0\n",
      "2  None  30.0    Male  55000.0\n",
      "3  Anna  28.0  Female  62000.0\n",
      "4  Mark  32.0    Male      NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a small dataset\n",
    "data = {\n",
    "    'Name': ['John', 'Jane', None, 'Anna', 'Mark'],\n",
    "    'Age': [25, None, 30, 28, 32],\n",
    "    'Gender': ['male', 'Female', 'male', 'Female', 'Male'],\n",
    "    'Salary': [50000, 60000, 55000, 62000, None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# Standardize 'Gender' column\n",
    "df['Gender'] = df['Gender'].str.capitalize()\n",
    "# Just captilize the first letter of the gender male to Male. \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d67522-e258-4531-8264-fc898919d967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e210b-48db-4d3f-a2f1-66b8fc5b3c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "# Initial dataset\n",
    "data = {\n",
    "    'Name': ['John', 'Jane', None, 'Anna', 'Mark'],\n",
    "    'Age': [25, None, 30, 28, 32],\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male'],\n",
    "    'Salary': [50000, 60000, 55000, 62000, None]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Clean the dataset\n",
    "# Fill missing 'Age' and 'Salary' with their mean\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "df['Salary'].fillna(df['Salary'].mean(), inplace=True)\n",
    "\n",
    "# Drop rows with missing 'Name'\n",
    "df.dropna(subset=['Name'], inplace=True)\n",
    "\n",
    "# Ensure 'Age' and 'Salary' are of type float\n",
    "df['Age'] = df['Age'].astype(float)\n",
    "df['Salary'] = df['Salary'].astype(float)\n",
    "\n",
    "# Standardize the 'Gender' column\n",
    "df['Gender'] = df['Gender'].str.capitalize()\n",
    "\n",
    "# Display the cleaned dataset\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Cleaned Dataset\", dataframe=df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe83214-a990-4564-a5c7-d10522e23547",
   "metadata": {},
   "source": [
    "Result\n",
    "   Name    Age  Gender   Salary\n",
    "0  John  25.00    Male  50000.0\n",
    "1  Jane  28.75  Female  60000.0\n",
    "3  Anna  28.00  Female  62000.0\n",
    "4  Mark  32.00    Male  56750.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "674e733c-8385-4c86-b825-37ae5ea75f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name    Age  Gender   Salary\n",
      "0  John  25.00    Male  50000.0\n",
      "1  Jane  28.75  Female  60000.0\n",
      "3  Anna  28.00  Female  62000.0\n",
      "4  Mark  32.00    Male  56750.0\n"
     ]
    }
   ],
   "source": [
    "# Remove outliers using z-scores (z > 3)\n",
    "from scipy import stats\n",
    "df = df[(np.abs(stats.zscore(df['Salary'])) < 3)]\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7479da72-a288-410c-8242-8b7b9b4d4046",
   "metadata": {},
   "source": [
    "## Data Normalization and Scaling\n",
    "When you have numerical columns with very different scales (e.g., income in thousands vs. age in years), you might want to normalize or scale the data. This is important for algorithms that rely on distances between data points (e.g., k-nearest neighbors, clustering).\n",
    "\n",
    "Normalization: Rescaling the data to fit within a specific range (e.g., between 0 and 1).\n",
    "Standardization: Centering the data around the mean with a unit standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af311e0d-bf3f-488d-8e16-aefe483c9375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name    Age  Gender    Salary\n",
      "0  John  25.00    Male  0.000000\n",
      "1  Jane  28.75  Female  0.833333\n",
      "3  Anna  28.00  Female  1.000000\n",
      "4  Mark  32.00    Male  0.562500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df['Salary'] = scaler.fit_transform(df[['Salary']])\n",
    "print(df)\n",
    "## Dealing with specific range between 0 and 1 convert the values in Salary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f225ff-9217-4106-add7-ac6d56ae669c",
   "metadata": {},
   "source": [
    "## Encoding Categorical Variables\n",
    "If you have categorical data (e.g., \"Male\", \"Female\"), many machine learning models can't process them directly. You can encode these categories numerically.\n",
    "\n",
    "Label Encoding: Assign a unique number to each category.\n",
    "One-Hot Encoding: Create binary columns for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26e15474-3f45-49c4-a387-37bf8b408a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name    Age    Salary  Gender_Female  Gender_Male\n",
      "0  John  25.00  0.000000          False         True\n",
      "1  Jane  28.75  0.833333           True        False\n",
      "3  Anna  28.00  1.000000           True        False\n",
      "4  Mark  32.00  0.562500          False         True\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding for 'Gender' column\n",
    "df = pd.get_dummies(df, columns=['Gender'])\n",
    "print(df)\n",
    "# converting gender to true or false to make computers life easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3ae6e-42ca-4efe-85f0-5e4d1eddd9cb",
   "metadata": {},
   "source": [
    "## Imputing Missing Data\n",
    "In addition to filling missing values with the mean, you can use other methods to impute missing values:\n",
    "\n",
    "Median or Mode: For skewed distributions, use the median instead of the mean.\n",
    "Forward/Backward Fill: For time-series data, you can propagate the last or next valid value.\n",
    "KNN Imputation: Use the k-nearest neighbors algorithm to impute missing values based on similarity between data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3482ef2-fcf9-4e7a-914f-252311c723c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name    Age    Salary  Gender_Female  Gender_Male\n",
      "0  John  25.00  0.000000          False         True\n",
      "1  Jane  28.75  0.833333           True        False\n",
      "3  Anna  28.00  1.000000           True        False\n",
      "4  Mark  32.00  0.562500          False         True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jandr\\AppData\\Local\\Temp\\ipykernel_6564\\2135991374.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Forward fill missing data in a time-series dataset\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37634594-c293-4551-a489-3bd47bab2280",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Sometimes, you can clean a dataset by creating new, more informative features or modifying existing ones:\n",
    "\n",
    "Binning: Convert continuous data into discrete categories (e.g., bin ages into groups like 20-29, 30-39).\n",
    "Date Feature Extraction: Extract year, month, or day from a date column for better analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c56191e1-9fd6-4cf7-b824-f511a326c695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name    Age    Salary  Gender_Female  Gender_Male Age_Group\n",
      "0  John  25.00  0.000000          False         True     20-30\n",
      "1  Jane  28.75  0.833333           True        False     20-30\n",
      "3  Anna  28.00  1.000000           True        False     20-30\n",
      "4  Mark  32.00  0.562500          False         True     30-40\n"
     ]
    }
   ],
   "source": [
    "# Binning ages into groups\n",
    "df['Age_Group'] = pd.cut(df['Age'], bins=[20, 30, 40], labels=['20-30', '30-40'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68d06c8-6d96-483c-8782-abc912ff9734",
   "metadata": {},
   "source": [
    "## Handling Duplicates with Aggregation\n",
    "Sometimes, you donâ€™t want to remove duplicates outright, but instead aggregate them in a meaningful way (e.g., summing or averaging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fbed94df-fed8-435f-b96c-d8822c13aca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Salary\n",
      "Name          \n",
      "Anna  1.000000\n",
      "Jane  0.833333\n",
      "John  0.000000\n",
      "Mark  0.562500\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Name' and aggregate salaries\n",
    "df = df.groupby('Name').agg({'Salary': 'mean'})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dc974b-8ee0-4dc2-be87-45caf23c8460",
   "metadata": {},
   "source": [
    "## Handling Text Data (Text Cleaning)\n",
    "For datasets with text data, you can clean the text by:\n",
    "\n",
    "Removing punctuation or special characters.\n",
    "Lowercasing text.\n",
    "Removing stopwords like \"and\", \"the\", \"is\".\n",
    "Stemming/Lemmatization: Reducing words to their base or root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c52b7d92-e39c-4b31-a943-4b3779a7cafb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Example: Clean text data by removing special characters\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, x\u001b[38;5;241m.\u001b[39mlower()))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Text'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Example: Clean text data by removing special characters\n",
    "df['Text'] = df['Text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x.lower()))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a4493-c309-412b-88f1-a0004e893dbf",
   "metadata": {},
   "source": [
    "## Handling Inconsistent Data Entry\n",
    "Data entry errors often introduce inconsistencies in the dataset (e.g., \"NY\", \"New York\", and \"ny\" all representing the same city).\n",
    "\n",
    "Standardize formats: Use string methods to unify the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3050bad5-d478-4b2f-a763-54d8ef67089f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'City'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'City'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Standardize the 'City' column to all uppercase\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mupper()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'City'"
     ]
    }
   ],
   "source": [
    "# Standardize the 'City' column to all uppercase\n",
    "df['City'] = df['City'].str.upper()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d998a6-48b5-462f-813a-3ae53263b706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
